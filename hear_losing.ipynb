{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "# TWB2 data\n",
    "TWB2_data = pd.read_csv('TWB2_data.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_id(ids, file_name):\n",
    "    d = {'FID': list(ids), 'IID': list(ids)}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    df.to_csv(file_name, header=False, index=None, sep=' ', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save sample ids with hear losing value in \n",
    "save_id(TWB2_data[~pd.isna(TWB2_data['I_32'])]['TWB2_ID'], 'TWB2_hear_lossing_id.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples with hear losing values in cleaned_TWB2_bfile \n",
    "hearing_loss_cleaned_id = pd.read_csv('hear_lossing.fam',sep=' ',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hear_losing_value for association analysis\n",
    "TWB2_hearing_loss_data = TWB2_data[~pd.isna(TWB2_data['I_32'])&TWB2_data['TWB2_ID'].isin(hearing_loss_cleaned_id[0])]\n",
    "TWB2_hearing_loss_data[['TWB2_ID','I_32']].to_csv('hear_losing_value.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# origin of hear losing sample\n",
    "Holo_id = TWB2_hearing_loss_data[(TWB2_hearing_loss_data['NATIVE_MOM_F']== 1) & (TWB2_hearing_loss_data['NATIVE_FA_F']== 1)]['TWB2_ID']\n",
    "Hakka_id = TWB2_hearing_loss_data[(TWB2_hearing_loss_data['NATIVE_MOM_H']== 1) & (TWB2_hearing_loss_data['NATIVE_FA_H']== 1)]['TWB2_ID']\n",
    "Chinese_id = TWB2_hearing_loss_data[(TWB2_hearing_loss_data['NATIVE_MOM_CHINA']== 1) & (TWB2_hearing_loss_data['NATIVE_FA_CHINA']== 1)]['TWB2_ID']\n",
    "other_id = TWB2_hearing_loss_data[~TWB2_hearing_loss_data['TWB2_ID'].isin(Holo_id.to_list()+Hakka_id.to_list()+Chinese_id.to_list())]['TWB2_ID']\n",
    "origin = dict(zip(Holo_id.to_list()+Hakka_id.to_list()+Chinese_id.to_list(),np.concatenate((np.repeat('Holo',len(Holo_id)), np.repeat('Hakka',len(Hakka_id)), np.repeat('Chinese',len(Chinese_id))), axis=0)))\n",
    "origin.update(dict(zip(other_id, np.repeat('Other', len(other_id)))))                                        \n",
    "                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save origin\n",
    "df = pd.DataFrame(origin.items())\n",
    "df.to_csv('origin.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get phenotypes for model building & define a binary variance 'hear_losing'\n",
    "TWB2_hearing_loss_phenotype_data = TWB2_hearing_loss_data[['TWB2_ID','AGE','I_32']]\n",
    "TWB2_hearing_loss_phenotype_data['hear_losing'] = (TWB2_hearing_loss_phenotype_data['I_32'] > 0).astype(int).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save phenotype data\n",
    "TWB2_hearing_loss_phenotype_data.to_csv('TWB2_hearing_loss_phenotype_data',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
